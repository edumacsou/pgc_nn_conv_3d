{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Meta Platforms, Inc. and affiliates. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deform a source mesh to form a target mesh using 3D loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we learn to deform an initial generic shape (e.g. sphere) to fit a target shape.<br>\n",
    "<br>\n",
    "We will cover: <br>\n",
    "<br>\n",
    "- How to **load a mesh** from an `.obj` file<br>\n",
    "- How to use the PyTorch3D **Meshes** datastructure<br>\n",
    "- How to use 4 different PyTorch3D **mesh loss functions**<br>\n",
    "- How to set up an **optimization loop**<br>\n",
    "<br>\n",
    "<br>\n",
    "Starting from a sphere mesh, we learn the offset to each vertex in the mesh such that<br>\n",
    "the predicted mesh is closer to the target mesh at each optimization step. To achieve this we minimize:<br>\n",
    "<br>\n",
    "+ `chamfer_distance`, the distance between the predicted (deformed) and target mesh, defined as the chamfer distance between the set of pointclouds resulting from **differentiably sampling points** from their surfaces. <br>\n",
    "<br>\n",
    "However, solely minimizing the chamfer distance between the predicted and the target mesh will lead to a non-smooth shape (verify this by setting  `w_chamfer=1.0` and all other weights to `0.0`). <br>\n",
    "<br>\n",
    "We enforce smoothness by adding **shape regularizers** to the objective. Namely, we add:<br>\n",
    "<br>\n",
    "+ `mesh_edge_length`, which minimizes the length of the edges in the predicted mesh.<br>\n",
    "+ `mesh_normal_consistency`, which enforces consistency across the normals of neighboring faces.<br>\n",
    "+ `mesh_laplacian_smoothing`, which is the laplacian regularizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install and Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure `torch` and `torchvision` are installed. If `pytorch3d` is not installed, install it using the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "need_pytorch3d=False\n",
    "try:\n",
    "    import pytorch3d\n",
    "except ModuleNotFoundError:\n",
    "    need_pytorch3d=True\n",
    "# if need_pytorch3d:\n",
    "#     if torch.__version__.startswith(\"2.2.\") and sys.platform.startswith(\"linux\"):\n",
    "#         # We try to install PyTorch3D via a released wheel.\n",
    "#         pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "#         version_str=\"\".join([\n",
    "#             f\"py3{sys.version_info.minor}_cu\",\n",
    "#             torch.version.cuda.replace(\".\",\"\"),\n",
    "#             f\"_pyt{pyt_version_str}\"\n",
    "#         ])\n",
    "#         # get_ipython().system('pip install fvcore iopath')\n",
    "#         # get_ipython().system('pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html')\n",
    "#     else:\n",
    "        # We try to install PyTorch3D from source.\n",
    "        # get_ipython().system(\"pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from scipy.special import comb\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "# get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CPU only, this will be slow!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARNING: CPU only, this will be slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free Form Deformation (FFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFD(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        return grad_output * 1.5 * (5 * input ** 2 - 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFD:\n",
    "    def __init__(self, l, m, n):\n",
    "        \"\"\"\n",
    "        l, m, n são o número de pontos de controle na grade em cada dimensão.\n",
    "        \"\"\"\n",
    "        self.l = l\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.dimension = (l, m, n)\n",
    "        # Inicializamos a grade de controle como uma grade uniforme no espaço [0,1]^3\n",
    "        self.control_points = np.array([[[[i/(l-1), j/(m-1), k/(n-1)] for k in range(n)] for j in range(m)] for i in range(l)])\n",
    "        \n",
    "        # self.control_points = 2 * self.control_points - 1\n",
    "    \n",
    "    def bernstein(self, i, n, u):\n",
    "        \"\"\"Função de base de Bernstein.\"\"\"\n",
    "        return comb(n, i) * (u**i) * ((1 - u)**(n - i))\n",
    "    \n",
    "    def derivative_bernstein(self, i, n, u):\n",
    "        \"\"\"Derivada da função de base de Bernstein usada algoritmo de backpropagation\"\"\"\n",
    "        return -u**(-1+i) * comb(n, i) * (n*u-i) * ((1-u)**(n-1-i))\n",
    "    \n",
    "    def deform_points(self, points, control_points_delta):\n",
    "        \"\"\"\n",
    "        Deforma os pontos da malha usando a grade de controle deformada.\n",
    "        points: np.array de formato (N, 3), contendo os pontos da malha.\n",
    "        control_points_delta: np.array de formato (l, m, n, 3) com os deslocamentos da grade de controle.\n",
    "        \"\"\"\n",
    "\n",
    "        # Atualiza os pontos da grade de controle com o deslocamento\n",
    "        control_points = self.control_points + control_points_delta\n",
    "        \n",
    "        deformed_points = np.zeros(points.shape)\n",
    "        deformed_points_deltas = np.zeros(points.shape)\n",
    "        \n",
    "        for p_idx, p in enumerate(points):\n",
    "            u, v, w = p  # Assumimos que os pontos estão normalizados no intervalo [0,1]\n",
    "            \n",
    "            new_point = np.zeros(3)\n",
    "            \n",
    "            for i in range(self.l):\n",
    "                for j in range(self.m):\n",
    "                    for k in range(self.n):\n",
    "                        # Calculamos a contribuição de cada ponto de controle usando Bernstein\n",
    "                        B_i = self.bernstein(i, self.l - 1, u)\n",
    "                        B_j = self.bernstein(j, self.m - 1, v)\n",
    "                        B_k = self.bernstein(k, self.n - 1, w)\n",
    "                        \n",
    "                        # Calculamos a posição deformada somando a contribuição ponderada de cada ponto de controle\n",
    "                        new_point += B_i * B_j * B_k * control_points[i, j, k]\n",
    "                    \n",
    "            deformed_points[p_idx] = new_point\n",
    "            deformed_points_deltas[p_idx] = new_point - points[p_idx]\n",
    "        \n",
    "        return deformed_points, deformed_points_deltas\n",
    "    \n",
    "    def deform_mesh(self, mesh, control_points_delta_array):\n",
    "        \"\"\"\n",
    "        Deforma os pontos da malha usando a grade de controle deformada.\n",
    "        points: np.array de formato (N, 3), contendo os pontos da malha.\n",
    "        control_points_delta: np.array de formato (l, m, n, 3) com os deslocamentos da grade de controle.\n",
    "        \"\"\"\n",
    "        control_points_delta = control_points_delta_array.detach().numpy().reshape(self.dimension + (3,))\n",
    "        mesh_verts = mesh.verts_packed().detach().cpu().numpy()\n",
    "        mesh_verts = mesh_verts / 2 + 0.5\n",
    "        _, deformed_mesh_points_deltas = self.deform_points(mesh_verts, control_points_delta)\n",
    "        \n",
    "        deformed_mesh_points_deltas_tensor = torch.tensor(deformed_mesh_points_deltas, requires_grad=True)\n",
    "\n",
    "        # Cria nova malha substituindo os pontos originais pelos deformados\n",
    "        new_mesh = mesh.offset_verts(deformed_mesh_points_deltas_tensor.float())\n",
    "        return new_mesh\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize the source and target meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    def plot_deformation(self, original_points, deformed_points, control_points_delta):\n",
    "        \"\"\"\n",
    "        Plota a malha e a grade de controle antes e depois da deformação.\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Posição dos pontos de controle deformados\n",
    "        deformed_control_points = self.control_points + control_points_delta\n",
    "        \n",
    "        # Plot original e deformado lado a lado\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        \n",
    "        # Plotando malha original\n",
    "        ax1.scatter(original_points[:, 0], original_points[:, 1], original_points[:, 2], color='blue', label='Malha Original')\n",
    "        ax2.scatter(original_points[:, 0], original_points[:, 1], original_points[:, 2], color='blue', marker='^', label='Malha Original')\n",
    "        ax2.scatter(deformed_points[:, 0], deformed_points[:, 1], deformed_points[:, 2], color='red', label='Malha Deformada')\n",
    "        \n",
    "        # Função para plotar as linhas de controle da grade\n",
    "        def plot_control_grid(ax, control_points, title):\n",
    "            for i in range(self.l):\n",
    "                for j in range(self.m):\n",
    "                    for k in range(self.n):\n",
    "                        ax.scatter(*control_points[i, j, k], color='black')\n",
    "            \n",
    "            # Conecta os pontos ao longo de cada eixo\n",
    "            # Conectar ao longo do eixo X\n",
    "            for j in range(self.m):\n",
    "                for k in range(self.n):\n",
    "                    for i in range(self.l - 1):\n",
    "                        ax.plot([control_points[i, j, k][0], control_points[i + 1, j, k][0]],\n",
    "                                [control_points[i, j, k][1], control_points[i + 1, j, k][1]],\n",
    "                                [control_points[i, j, k][2], control_points[i + 1, j, k][2]],\n",
    "                                color='gray')\n",
    "            \n",
    "            # Conectar ao longo do eixo Y\n",
    "            for i in range(self.l):\n",
    "                for k in range(self.n):\n",
    "                    for j in range(self.m - 1):\n",
    "                        ax.plot([control_points[i, j, k][0], control_points[i, j + 1, k][0]],\n",
    "                                [control_points[i, j, k][1], control_points[i, j + 1, k][1]],\n",
    "                                [control_points[i, j, k][2], control_points[i, j + 1, k][2]],\n",
    "                                color='gray')\n",
    "\n",
    "            # Conectar ao longo do eixo Z\n",
    "            for i in range(self.l):\n",
    "                for j in range(self.m):\n",
    "                    for k in range(self.n - 1):\n",
    "                        ax.plot([control_points[i, j, k][0], control_points[i, j, k + 1][0]],\n",
    "                                [control_points[i, j, k][1], control_points[i, j, k + 1][1]],\n",
    "                                [control_points[i, j, k][2], control_points[i, j, k + 1][2]],\n",
    "                                color='gray')\n",
    "            \n",
    "            ax.set_title(title)\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_zlabel('Z')\n",
    "            ax.set_aspect('equal', adjustable='box')\n",
    "        \n",
    "        # Plotando a grade de controle\n",
    "        plot_control_grid(ax1, self.control_points, \"Malha e Grade Originais\")\n",
    "        plot_control_grid(ax2, deformed_control_points, \"Malha e Grade Deformadas\")\n",
    "        \n",
    "        ax1.legend()\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load an obj file and create a Meshes object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the target 3D model of a dolphin. It will be saved locally as a file called `dolphin.obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-05 20:13:25--  https://dl.fbaipublicfiles.com/pytorch3d/data/dolphin/dolphin.obj\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 52.84.83.109, 52.84.83.48, 52.84.83.26, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|52.84.83.109|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 156763 (153K) [text/plain]\n",
      "Saving to: ‘dolphin.obj’\n",
      "\n",
      "dolphin.obj         100%[===================>] 153.09K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-11-05 20:13:25 (1.37 MB/s) - ‘dolphin.obj’ saved [156763/156763]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('wget https://dl.fbaipublicfiles.com/pytorch3d/data/dolphin/dolphin.obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dolphin mesh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the target 3D model using load_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch3d/io/obj_io.py:544: UserWarning: No mtl file provided\n",
      "  warnings.warn(\"No mtl file provided\")\n"
     ]
    }
   ],
   "source": [
    "trg_obj = 'dolphin.obj'\n",
    "verts, faces, aux = load_obj(trg_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh<br>\n",
    "faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx<br>\n",
    "For this tutorial, normals and textures are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_idx = faces.verts_idx.to(device)\n",
    "verts = verts.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). <br>\n",
    "(scale, center) will be used to bring the predicted mesh to its original center and scale<br>\n",
    "Note that normalizing the target mesh, speeds up the optimization but is not necessary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = verts.mean(0)\n",
    "verts = verts - center\n",
    "scale = max(verts.abs().max(0)[0])\n",
    "verts = verts / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a Meshes structure for the target mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_mesh = Meshes(verts=[verts], faces=[faces_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the source shape to be a sphere of radius 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mesh = ico_sphere(4, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize the source and target meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pointcloud(mesh, title=\"\"):\n",
    "    # Sample points uniformly from the surface of the mesh.\n",
    "    points = sample_points_from_meshes(mesh, 5000)\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter3D(x, z, -y)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(190, 30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pointcloud(trg_mesh, \"Target mesh\")\n",
    "plot_pointcloud(src_mesh, \"Source mesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimization loop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiply = lambda x,y: x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_box_dimension = (3,3,3)\n",
    "# control_box_size = reduce(multiply, control_box_dimension)\n",
    "control_box_size = 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn to deform the source mesh by offsetting its vertices<br>\n",
    "The shape of the deform parameters is equal to the total number of vertices in src_mesh<br>\n",
    "deform_verts = torch.full(src_mesh.verts_packed().shape, 0.0, device=device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_control_points = torch.full(torch.Size([control_box_size, 3]), 0.0, device=device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My new version will use only the offset of the vertices wich defines the FFD bonderies<br>\n",
    "deform_verts_new = torch.full([num_boxes, 3], 0.0, device=device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer<br>\n",
    "params  = iterable of parameters to optimize<br>\n",
    "lr = learning rate<br>\n",
    "optimizer = torch.optim.SGD(params = [deform_verts], lr=1.0, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_control_box = torch.optim.SGD(params = [delta_control_points], lr=1.0, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffd = FFD(*control_box_dimension)\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of optimization steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Niter = 201\n",
    "# Weight for the chamfer loss\n",
    "w_chamfer = 1.0 \n",
    "# Weight for mesh edge loss\n",
    "w_edge = 1.0 \n",
    "# Weight for mesh normal consistency\n",
    "w_normal = 0.01 \n",
    "# Weight for mesh laplacian smoothing\n",
    "w_laplacian = 0.1 \n",
    "# Plot period for the losses\n",
    "plot_period = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chamfer_losses = []<br>\n",
    "laplacian_losses = []<br>\n",
    "edge_losses = []<br>\n",
    "normal_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chamfer_losses_ffd = []\n",
    "laplacian_losses_ffd = []\n",
    "edge_losses_ffd = []\n",
    "normal_losses_ffd = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Niter):\n",
    "    # Initialize optimizer\n",
    "    # optimizer.zero_grad()\n",
    "    optimizer_control_box.zero_grad()\n",
    "    \n",
    "    # Deform the mesh\n",
    "    # new_src_mesh = src_mesh.offset_verts(deform_verts)\n",
    "    new_src_mesh_ffd = ffd.deform_mesh(src_mesh, delta_control_points)\n",
    "    \n",
    "    # We sample 5k points from the surface of each mesh \n",
    "    sample_trg = sample_points_from_meshes(trg_mesh, 5000)\n",
    "    # sample_src = sample_points_from_meshes(new_src_mesh, 5000)\n",
    "    sample_src_ffd = sample_points_from_meshes(new_src_mesh_ffd, 5000)\n",
    "    \n",
    "    # We compare the two sets of pointclouds by computing (a) the chamfer loss\n",
    "    # loss_chamfer, _ = chamfer_distance(sample_trg, sample_src)\n",
    "    loss_chamfer_ffd, _ = chamfer_distance(sample_trg, sample_src_ffd)\n",
    "    \n",
    "    # and (b) the edge length of the predicted mesh\n",
    "    # loss_edge = mesh_edge_loss(new_src_mesh)\n",
    "    loss_edge_ffd = mesh_edge_loss(new_src_mesh_ffd)\n",
    "    \n",
    "    # mesh normal consistency\n",
    "    # loss_normal = mesh_normal_consistency(new_src_mesh)\n",
    "    loss_normal_ffd = mesh_normal_consistency(new_src_mesh_ffd)\n",
    "    \n",
    "    # mesh laplacian smoothing\n",
    "    # loss_laplacian = mesh_laplacian_smoothing(new_src_mesh, method=\"uniform\")\n",
    "    loss_laplacian_ffd = mesh_laplacian_smoothing(new_src_mesh_ffd, method=\"uniform\")\n",
    "    \n",
    "    # Weighted sum of the losses\n",
    "    # loss = loss_chamfer * w_chamfer + loss_edge * w_edge + loss_normal * w_normal + loss_laplacian * w_laplacian\n",
    "    loss_ffd = loss_chamfer_ffd * w_chamfer + loss_edge_ffd * w_edge + loss_normal_ffd * w_normal + loss_laplacian_ffd * w_laplacian\n",
    "    \n",
    "    # Print the losses\n",
    "    # print(f'iter{i}: total_loss = {loss:.6f}')\n",
    "    print(f'iter{i}: total_loss = {loss_ffd:.6f}')\n",
    "    \n",
    "    # Save the losses for plotting\n",
    "    # chamfer_losses.append(float(loss_chamfer.detach().cpu()))\n",
    "    # edge_losses.append(float(loss_edge.detach().cpu()))\n",
    "    # normal_losses.append(float(loss_normal.detach().cpu()))\n",
    "    # laplacian_losses.append(float(loss_laplacian.detach().cpu()))\n",
    "    chamfer_losses_ffd.append(float(loss_chamfer_ffd.detach().cpu()))\n",
    "    edge_losses_ffd.append(float(loss_edge_ffd.detach().cpu()))\n",
    "    normal_losses_ffd.append(float(loss_normal_ffd.detach().cpu()))\n",
    "    laplacian_losses_ffd.append(float(loss_laplacian_ffd.detach().cpu()))\n",
    "    \n",
    "    # Plot mesh\n",
    "    if i % plot_period == 0:\n",
    "        plot_pointcloud(new_src_mesh_ffd, title=\"iter: %d\" % i)\n",
    "        # plot_pointcloud(new_src_mesh, title=\"iter: %d\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Optimization step\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    loss_ffd.backward()\n",
    "    optimizer_control_box.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 5))\n",
    "ax = fig.gca()\n",
    "ax.plot(chamfer_losses, label=\"chamfer loss\")\n",
    "ax.plot(edge_losses, label=\"edge loss\")\n",
    "ax.plot(normal_losses, label=\"normal loss\")\n",
    "ax.plot(laplacian_losses, label=\"laplacian loss\")\n",
    "ax.legend(fontsize=\"16\")\n",
    "ax.set_xlabel(\"Iteration\", fontsize=\"16\")\n",
    "ax.set_ylabel(\"Loss\", fontsize=\"16\")\n",
    "ax.set_title(\"Loss vs iterations\", fontsize=\"16\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the predicted mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the verts and faces of the final predicted mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_verts, final_faces = new_src_mesh.get_mesh_verts_faces(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale normalize back to the original target size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_verts = final_verts * scale + center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the predicted mesh using save_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_obj = 'final_model.obj'\n",
    "save_obj(final_obj, final_verts, final_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion <br>\n",
    "<br>\n",
    "In this tutorial we learnt how to load a mesh from an obj file, initialize a PyTorch3D datastructure called **Meshes**, set up an optimization loop and use four different PyTorch3D mesh loss functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
